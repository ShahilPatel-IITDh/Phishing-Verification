{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm , preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score(scoring):\n",
    "    return {i:j.mean() for i,j in scoring.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data.\n",
    "- Load the data and clean it for unique values, later shuffle it with specific seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parent directory of the current folder\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Specify the file path for dataset.csv in the parent folder\n",
    "filename = os.path.join(parent_dir, \"dataset.csv\")\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Length of URL', 'Has IP address', 'Shortening Service',\n",
       "       'Having @ Symbol', 'Double Slash Redirecting', 'Prefix-Suffix',\n",
       "       'Standard Port', 'CTLD', 'HTTPS in Domain', 'Sensitive Words',\n",
       "       'Has Tilde', 'Has Port'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the column names have leading white spaces, we will rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={' Has IP address':'Has_IP_address', ' Shortening Service':'Shortening_Service', ' Having @ Symbol':'Having_@_Symbol', ' Double Slash Redirecting':'Double_Slash_Redirecting', ' Prefix-Suffix':'Prefix-Suffix', ' Standard Port':'Standard_Port', ' CTLD':'CTLD', ' HTTPS in Domain':'HTTPS_in_Domain', ' Sensitive Words':'Sensitive_Words', ' Has Tilde':'Has_Tilde', ' Has Port':'Has_Port', ' Result':'Result'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had merged two csv files to create a dataset, we need to check the unique values present in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Has_IP_address'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Has_IP_address'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Investigate unique values in the each column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m unique_IP \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mHas_IP_address\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      3\u001b[0m unique_SS \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mShortening_Service\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      4\u001b[0m unique_HAS \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mHaving_@_Symbol\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Has_IP_address'"
     ]
    }
   ],
   "source": [
    "# Investigate unique values in the each column\n",
    "unique_IP = df['Has_IP_address'].unique()\n",
    "unique_SS = df['Shortening_Service'].unique()\n",
    "unique_HAS = df['Having_@_Symbol'].unique()\n",
    "unique_DSR = df['Double_Slash_Redirecting'].unique()\n",
    "unique_PS = df['Prefix-Suffix'].unique()\n",
    "unique_SP = df['Standard_Port'].unique()\n",
    "unique_CTLD = df['CTLD'].unique()\n",
    "unique_HID = df['HTTPS_in_Domain'].unique()\n",
    "unique_SW = df['Sensitive_Words'].unique()\n",
    "unique_HT = df['Has_Tilde'].unique()\n",
    "unique_HP = df['Has_Port'].unique()\n",
    "unique_R = df['Result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1             ' ' -1            ' ' Has IP address']\n",
      "[' -1                ' ' 1                 ' ' Shortening Service']\n",
      "[' 1              ' ' -1             ' ' Having @ Symbol']\n",
      "[' 1                       ' ' -1                      '\n",
      " ' Double Slash Redirecting']\n",
      "[' -1           ' ' 1            ' ' Prefix-Suffix']\n",
      "[' 0            ' ' -1           ' ' Standard Port']\n",
      "[' 1   ' ' -1  ' ' 0   ' ' CTLD']\n",
      "[' -1             ' ' HTTPS in Domain']\n",
      "[' 1              ' ' -1             ' ' Sensitive Words']\n",
      "[' 1        ' ' -1       ' ' Has Tilde']\n",
      "[' -1      ' ' 1       ' ' Has Port']\n",
      "[' 1' ' Result' ' -1']\n"
     ]
    }
   ],
   "source": [
    "print(unique_IP)\n",
    "print(unique_SS)\n",
    "print(unique_HAS)\n",
    "print(unique_DSR)\n",
    "print(unique_PS)\n",
    "print(unique_SP)\n",
    "print(unique_CTLD)\n",
    "print(unique_HID)\n",
    "print(unique_SW)\n",
    "print(unique_HT)\n",
    "print(unique_HP)\n",
    "print(unique_R)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all the values other than {-1, 0, 1} from all the values of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validValues = {-1, 0, 1}\n",
    "\n",
    "for column in df.columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    df = df[df[column].isin(validValues)]\n",
    "\n",
    "# Convert all columns to integers (again after the filtering)\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length of URL  Has_IP_address  Shortening_Service  Having_@_Symbol  \\\n",
      "0                 1               1                  -1                1   \n",
      "1                 1               1                   1                1   \n",
      "2                 1               1                   1                1   \n",
      "3                 1               1                   1                1   \n",
      "4                 1               1                   1                1   \n",
      "...             ...             ...                 ...              ...   \n",
      "3211             -1               1                   1                1   \n",
      "3212              1               1                   1                1   \n",
      "3213             -1               1                   1                1   \n",
      "3214             -1               1                   1                1   \n",
      "3215              1               1                   1                1   \n",
      "\n",
      "      Double_Slash_Redirecting  Prefix-Suffix  Standard_Port  CTLD  \\\n",
      "0                            1             -1              0     1   \n",
      "1                            1              1              0     1   \n",
      "2                            1              1              0     1   \n",
      "3                            1              1              0    -1   \n",
      "4                            1              1              0     0   \n",
      "...                        ...            ...            ...   ...   \n",
      "3211                         1              1              0     1   \n",
      "3212                         1              1              0     1   \n",
      "3213                         1              1              0     1   \n",
      "3214                         1              1              0     0   \n",
      "3215                         1              1              0     0   \n",
      "\n",
      "      HTTPS_in_Domain  Sensitive_Words  Has_Tilde  Has_Port  Result  \n",
      "0                  -1                1          1        -1       1  \n",
      "1                  -1               -1          1        -1       1  \n",
      "2                  -1               -1          1        -1       1  \n",
      "3                  -1                1          1        -1       1  \n",
      "4                  -1                1          1        -1       1  \n",
      "...               ...              ...        ...       ...     ...  \n",
      "3211               -1                1          1        -1      -1  \n",
      "3212               -1               -1          1        -1      -1  \n",
      "3213               -1                1          1        -1      -1  \n",
      "3214               -1               -1          1        -1      -1  \n",
      "3215               -1                1          1        -1      -1  \n",
      "\n",
      "[3215 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the DataFrame with valid integer values (1, -1, and 0)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again check the unique values present in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate unique values in the each column\n",
    "unique_IP_2 = df['Has_IP_address'].unique()\n",
    "unique_SS_2 = df['Shortening_Service'].unique()\n",
    "unique_HAS_2 = df['Having_@_Symbol'].unique()\n",
    "unique_DSR_2 = df['Double_Slash_Redirecting'].unique()\n",
    "unique_PS_2 = df['Prefix-Suffix'].unique()\n",
    "unique_SP_2 = df['Standard_Port'].unique()\n",
    "unique_CTLD_2 = df['CTLD'].unique()\n",
    "unique_HID_2 = df['HTTPS_in_Domain'].unique()\n",
    "unique_SW_2 = df['Sensitive_Words'].unique()\n",
    "unique_HT_2 = df['Has_Tilde'].unique()\n",
    "unique_HP_2 = df['Has_Port'].unique()\n",
    "unique_R_2 = df['Result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1]\n",
      "[-1  1]\n",
      "[ 1 -1]\n",
      "[ 1 -1]\n",
      "[-1  1]\n",
      "[ 0 -1]\n",
      "[ 1 -1  0]\n",
      "[-1]\n",
      "[ 1 -1]\n",
      "[ 1 -1]\n",
      "[-1  1]\n",
      "[ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(unique_IP_2)\n",
    "print(unique_SS_2)\n",
    "print(unique_HAS_2)\n",
    "print(unique_DSR_2)\n",
    "print(unique_PS_2)\n",
    "print(unique_SP_2)\n",
    "print(unique_CTLD_2)\n",
    "print(unique_HID_2)\n",
    "print(unique_SW_2)\n",
    "print(unique_HT_2)\n",
    "print(unique_HP_2)\n",
    "print(unique_R_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 1 1675\n",
      "number of -1 1540\n"
     ]
    }
   ],
   "source": [
    "print(\"number of 1\",len(df[df[\"Result\"]==1]))\n",
    "print(\"number of -1\",len(df[df[\"Result\"]==-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing. \n",
    "- Shuffle the data and split it into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length of URL</th>\n",
       "      <th>Has_IP_address</th>\n",
       "      <th>Shortening_Service</th>\n",
       "      <th>Having_@_Symbol</th>\n",
       "      <th>Double_Slash_Redirecting</th>\n",
       "      <th>Prefix-Suffix</th>\n",
       "      <th>Standard_Port</th>\n",
       "      <th>CTLD</th>\n",
       "      <th>HTTPS_in_Domain</th>\n",
       "      <th>Sensitive_Words</th>\n",
       "      <th>Has_Tilde</th>\n",
       "      <th>Has_Port</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length of URL  Has_IP_address  Shortening_Service  Having_@_Symbol  \\\n",
       "516               1               1                   1                1   \n",
       "1008              1               1                  -1                1   \n",
       "694               0               1                   1                1   \n",
       "2091              1               1                   1                1   \n",
       "110              -1               1                   1                1   \n",
       "\n",
       "      Double_Slash_Redirecting  Prefix-Suffix  Standard_Port  CTLD  \\\n",
       "516                          1              1              0     1   \n",
       "1008                         1              1              0    -1   \n",
       "694                          1              1              0     1   \n",
       "2091                         1              1              0    -1   \n",
       "110                          1              1              0     0   \n",
       "\n",
       "      HTTPS_in_Domain  Sensitive_Words  Has_Tilde  Has_Port  Result  \n",
       "516                -1                1          1        -1       1  \n",
       "1008               -1                1          1        -1       1  \n",
       "694                -1                1          1        -1       1  \n",
       "2091               -1                1          1        -1      -1  \n",
       "110                -1                1          1        -1       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sklearn.utils.shuffle(df)\n",
    "X = df.drop(\"Result\",axis=1).values\n",
    "X = preprocessing.scale(X)\n",
    "y = df['Result'].values\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution metrics \n",
    " - Specifying evaluation metrics for classification models\n",
    " - Using 10 fold-cross-validation for evaluting "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)\n",
    "- Recall = (True Positives) / (True Positives + False Negatives)\n",
    "- Precision = (True Positives) / (True Positives + False Positives)\n",
    "- F1 score = 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy': 'accuracy',\n",
    "           'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'f1': 'f1'}\n",
    "fold_count=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time = 0.002201676368713379\n",
      "score time = 0.004827141761779785\n",
      "accuracy = 0.6239275555813549\n",
      "recall = 0.7246970345024237\n",
      "precision = 0.6194377262592194\n",
      "f1 = 0.6673615542791367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_clf=DecisionTreeClassifier()\n",
    "cross_val_scores = cross_validate(dtree_clf, X, y, cv=fold_count, scoring=scoring)\n",
    "dtree_score = mean_score(cross_val_scores)\n",
    "print(f\"fit time = {dtree_score['fit_time']}\")\n",
    "print(f\"score time = {dtree_score['score_time']}\")\n",
    "print(f\"accuracy = {dtree_score['test_accuracy']}\")\n",
    "print(f\"recall = {dtree_score['test_recall']}\")\n",
    "print(f\"precision = {dtree_score['test_precision']}\")\n",
    "print(f\"f1 = {dtree_score['test_f1']}\")\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
